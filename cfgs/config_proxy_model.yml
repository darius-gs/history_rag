llm:
    proxy_model: true
    name: "chatglm3-6b-32k"
    temperature: 0.01
    api_base: "http://x.x.x.x/api/v1"
    api_key: "EMPTY"
embedding:
    name: "BAAI/bge-base-zh-v1.5"
    dim: 768 
rerank:
    name: "BAAI/bge-reranker-large"
milvus:
    host: "localhost" 
    port: "19530"
    collection_name: "history_rag"
    retrieve_topk: 500
    window_size: 4
    rerank_topk: 15
pipeline:
    collection_name: "history_rag" 
    chunk_size: 500
    retrieve_topk: 8
    


